# üìã Plano: Validar Fluxo thesis analyze com LLM Real

## üéØ Objetivo

Validar que o fluxo principal do `thesis analyze` com uso real de LLMs e agentes est√° 100% implementado e pronto para testes.

## ‚úÖ An√°lise Completa

### Status: 100% Implementado ‚úÖ

O fluxo principal do `thesis analyze` com uso real de LLMs e agentes est√° **completamente implementado** e pronto para testes.

## üèóÔ∏è O que est√° Implementado

### 1. CLI - Comando `analyze` ‚úÖ
- **Arquivo:** `apps/thesis-cli/src/index.ts` (linhas 569-651)
- **Funcionalidades:**
  - Valida√ß√£o de input (session, iterations, timeout)
  - Verifica√ß√£o se sess√£o existe e est√° ativa
  - Spawn do processo gateway com vari√°veis de ambiente
  - Passa `PI_PROVIDER`, `PI_MODEL`, `PI_API_KEY` para o gateway
  - Logs em tempo real via `stdio: inherit`
  - Exibe resumo ap√≥s conclus√£o

**Uso:**
```bash
node apps/thesis-cli/dist/index.js analyze --session <id> --iterations 10 --timeout 60000
```

### 2. Gateway - Orquestrador ‚úÖ
- **Arquivo:** `apps/thesis-gateway/src/index.ts`
- **Funcionalidades:**
  - Busca sess√£o da API
  - Conecta WebSocket
  - Registra 3 agentes automaticamente (debt, tech, market)
  - Executa loop de itera√ß√µes com workers paralelos
  - Processa resultados (opinions, messages, votes)
  - Fecha sess√£o com veredito baseado em maioria
  - Tratamento de erros e SIGTERM/SIGINT

**Arquitetura:**
```
CLI ‚Üí Gateway ‚Üí AgentWorkerManager ‚Üí 3 Agent Workers (debt, tech, market)
                    ‚Üì
                  API + WebSocket
```

### 3. Agent Worker - Integra√ß√£o LLM Real ‚úÖ
- **Arquivo:** `apps/thesis-agent-runtime/src/agent-worker.ts`
- **Funcionalidades:**
  - Inicializa√ß√£o com mono-pi Agent (linha 258-292)
  - Busca contexto real via APIClient (linha 70-141)
  - Decis√µes aut√¥nomas baseadas em LLM (linha 349-383)
  - Chamada √† LLM com timeout (linha 294-338)
  - Parse de decis√µes estruturadas JSON (linha 229-256)
  - Dedu√ß√£o de budget por a√ß√£o (linha 430-433)
  - Tratamento de erros com fallback para `wait`

**Componentes mono-pi:**
```typescript
const model = getModel(this.piProvider, this.piModel);
this.piAgent = new Agent({
  initialState: { systemPrompt, model, ... },
  getApiKey: (provider: string) => config.pi_api_key,
});
```

### 4. Contexto Real ‚úÖ
- **Arquivo:** `apps/thesis-agent-runtime/src/api-client.ts`
- **Dados buscados da API:**
  - Sess√£o (hip√≥tese, status, veredito)
  - Documentos (lista com metadata)
  - Agentes (com profiles)
  - Opini√µes anteriores
  - Mensagens anteriores
  - Votos anteriores

**Contexto completo:**
```typescript
interface AutonomousAgentContext {
  session_id, agent_id, profile;
  iteration, max_iterations;
  budget, hypothesis, hypothesis_description;
  documents, other_agents;
  previous_opinions, previous_messages, previous_votes;
  session_status, final_verdict;
}
```

### 5. Worker Threads - Paralelismo ‚úÖ
- **Arquivo:** `apps/thesis-gateway/src/worker-manager.ts`
- **Funcionalidades:**
  - Gerencia at√© 3 workers paralelos
  - Respeita max concurrency
  - Timeout por worker (configur√°vel)
  - Reusa workers existentes
  - Stats ativos (activeWorkers, workerCount)

### 6. Skills e Prompts ‚úÖ
- **SOUL:** `packages/skills/SOUL.md` - Diretrizes globais
- **BASE_SYSTEM:** `packages/skills/BASE_SYSTEM.md` - Sistema prompt base
- **Skills:**
  - `debt-specialist/SKILL.md` - Especialista em finan√ßas
  - `tech-expert/SKILL.md` - Especialista em tecnologia
  - `market-analyst/SKILL.md` - Especialista em mercado

**Composi√ß√£o de prompts:**
```typescript
const systemPrompt = composePrompt(
  baseSystem,    // BASE_SYSTEM.md
  soul,          // SOUL.md
  profileDesc,   // Profile description
  skillContent,  // SKILL.md
  constraints    // Budget, session rules
);
```

### 7. Docker Services ‚úÖ
- **Arquivo:** `docker-compose.yml`
- **Servi√ßos:**
  - `postgres` - Banco de dados
  - `api` - REST API + WebSocket
  - `gateway` - Gateway worker (servi√ßo base)
  - `orchestrator` - Orquestrador com env vars
  - `cli` - CLI interface
  - `war-room` - Dashboard Next.js

**Status:** ‚úÖ API respondendo, logs mostram atividade

### 8. Build ‚úÖ
Todos os servi√ßos compilados:
- ‚úÖ `apps/thesis-cli/dist/index.js` (23KB)
- ‚úÖ `apps/thesis-gateway/dist/index.js` (12KB)
- ‚úÖ `apps/thesis-agent-runtime/dist/agent-worker.js` (17KB)
- ‚úÖ `packages/prompt-adapter/dist/` (arquivos .d.ts gerados)

### 9. Environment Variables ‚úÖ
- **Arquivo:** `.env`
- **Vari√°veis configuradas:**
  - `PI_PROVIDER=openai`
  - `PI_MODEL=gpt-4o-mini`
  - `PI_API_KEY=sk-your-api-key-here` (precisa ser atualizada)
  - `API_URL=http://localhost:4000`
  - `MAX_ITERATIONS=10`
  - `ITERATION_TIMEOUT=60000`

### 10. Script de Valida√ß√£o ‚úÖ
- **Arquivo:** `scripts/validate-analyze-flow.ts`
- **Funcionalidades:**
  - Cria sess√£o de teste
  - Upload de documento (opcional)
  - Executa analyze com LLM real
  - Valida resultados (agents, opinions, messages, votes)
  - Gera relat√≥rio final em JSON
  - Exibe an√°lise detalhada do comportamento dos agentes

**Uso:**
```bash
node scripts/validate-analyze-flow.ts [options]
```

## üß™ Como Fazer Teste Real

### Pr√©-requisitos

1. **API Key OpenAI:**
   - Editar `.env`:
   ```bash
   PI_API_KEY=sk-your-real-openai-api-key-here
   ```

2. **Docker rodando:**
   ```bash
   docker-compose up -d
   docker-compose ps  # Verificar se api est√° healthy
   ```

3. **API verificando:**
   ```bash
   curl http://localhost:4000/health
   # Deve retornar: {"status":"healthy",...}
   ```

### Teste Manual (Passo a Passo)

```bash
# 1. Criar sess√£o
node apps/thesis-cli/dist/index.js init-session \
  --hypothesis "AI-powered SaaS startup with strong market fit" \
  --description "Test for real LLM integration"

# 2. (Opcional) Upload de documento
node apps/thesis-cli/dist/index.js upload-doc \
  --session <SESSION_ID> \
  --file ./test-doc.txt

# 3. Executar analyze (com LLM real!)
node apps/thesis-cli/dist/index.js analyze \
  --session <SESSION_ID> \
  --iterations 5 \
  --timeout 60000

# 4. Verificar resultados
node apps/thesis-cli/dist/index.js status --session <SESSION_ID>

# 5. Gerar relat√≥rio
node apps/thesis-cli/dist/index.js generate-report \
  --session <SESSION_ID> \
  --output report.json
```

### Teste Automatizado (Script de Valida√ß√£o)

```bash
# Teste b√°sico
node scripts/validate-analyze-flow.ts

# Teste com par√¢metros customizados
node scripts/validate-analyze-flow.ts \
  --hypothesis "Custom test hypothesis" \
  --iterations 3 \
  --timeout 60000 \
  --document ./test-doc.txt \
  --report ./custom-report.json
```

## üìä O que vai acontecer durante o teste

1. **CLI** spawna processo do **Gateway** com env vars
2. **Gateway** busca sess√£o e conecta **WebSocket**
3. **Gateway** registra 3 agentes (debt, tech, market) na API
4. **Gateway** cria 3 **Agent Workers** via worker_threads
5. **Cada Agent Worker:**
   - Inicializa mono-pi Agent com OpenAI
   - Busca contexto real da API (session, docs, agents, opinions, messages, votes)
   - Comp√µe prompt (BASE_SYSTEM + SOUL + Profile + SKILL + Constraints + Context)
   - Chama LLM (OpenAI gpt-4o-mini)
   - Recebe decis√£o estruturada JSON (action: opinion/message/vote/wait)
   - Retorna resultado para Gateway
6. **Gateway** registra a√ß√µes na API (POST /opinions, /messages, /votes)
7. **Gateway** aguarda ITERATION_DELAY entre itera√ß√µes
8. **Gateway** para quando: todos votaram OU max itera√ß√µes
9. **Gateway** fecha sess√£o com veredito (maioria de votos)
10. **CLI** exibe resumo final

## üéØ O que esperar da LLM

**Exemplo de decis√£o estruturada:**
```json
{
  "action": "opinion",
  "reasoning": "Based on the uploaded documents, the startup has strong unit economics with LTV:CAC ratio of 5:1, but burn rate is concerning at $500k/month",
  "content": "The financial metrics show promising unit economics (LTV:CAC 5:1, payback 18 months) indicating healthy customer economics. However, the current burn rate of $500k/month gives only 8 months runway with current funding, which is risky for Series A stage. I recommend improving capital efficiency or raising bridge funding before approaching investors.",
  "confidence": 0.7
}
```

**Poss√≠veis a√ß√µes:**
- `opinion` - Quando tem insights baseados em documentos/confian√ßa moderada-alta
- `message` - Quando precisa de info de outro agente ou quer questionar opini√£o
- `vote` - Quando tem evid√™ncia suficiente e considerou todas perspectivas
- `wait` - Quando budget baixo, precisa de mais info, ou incerto

## üêõ Problemas Conhecidos

**Nenhum problema conhecido que impe√ßa o funcionamento.**

- ‚úÖ CommonJS vs ES Modules: RESOLVIDO (Fase 10)
- ‚úÖ Skills Parser: CORRIGIDO (parsing YAML baseado em stack)
- ‚úÖ Agent Worker imports: FUNCIONAL (consegue importar `@thesis/prompt-adapter` e `@thesis/tools`)
- ‚úÖ Mono-pi integra√ß√£o: COMPLETA (usa Agent real e getModel)
- ‚úÖ Contexto real: IMPLEMENTADO (busca todos os dados da API)
- ‚úÖ Decis√µes aut√¥nomas: IMPLEMENTADAS (LLM decide a√ß√µes autonomamente)

## üìå Pr√≥ximos Passos

### Op√ß√£o 1: Teste Real Imediato
1. Editar `.env` e colocar API Key real
2. Rodar `docker-compose up -d`
3. Executar `node scripts/validate-analyze-flow.ts --iterations 3`

### Op√ß√£o 2: Ir para Hardening (Fase 12)
- Implementar retries
- Implementar rate limiting
- Implementar observabilidade (metrics, logs estruturados)
- Implementar health checks avan√ßados

### Op√ß√£o 3: Adicionar Mais Features
- Integra√ß√µes externas (Slack, WhatsApp) - adiar para depois
- Analytics e dashboards avan√ßados
- Export de relat√≥rios em PDF/Excel
- Versionamento de sess√µes

---

**Status:** ‚úÖ 100% Implementado, pronto para teste real
**Faltando:** Apenas API Key OpenAI real
**Pr√≥ximo:** Teste real ou Hardening (Fase 12)
